```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Pregunta 1

Una distribución muy usada para el análisis de datos bimodales es la distribución de mixtura de normales cuya función de densidad es dada por

$$f_X(x) = p\phi(x|\mu_1,\sigma_1^2)+(1-p)\phi(x|\mu_2,\sigma_2^2), x \in \mathbb{R}$$
donde $\mu_1,\mu_2 \in \mathbb{R}$, $\sigma_1^2,\sigma_2^2 > 0$, $p \in (0,1)$ y $\phi(.|a,b^2)$ representa la densidad de una distribución normal con media $a$ y varianza $b^2$. Utilizaremos la siguiente notación para una variable aleatoria $X$ que siga esta distribución: $X \sim \text{MN}(\mu_1,\mu_2,\sigma_1^2,\sigma_2^2,p)$

a) Encuentre una expresión para la media y la varianza de esta distribución.

Definimos $\phi_i = \phi(x|\mu_i,\sigma_i^2)$ y procedemos a hallar la media:

\begin{align}
\text{E}\left[X\right] &= \int_{-\infty}^\infty x(p\phi_1 + (1-p)\phi_2)dx\\
&= \int_{-\infty}^\infty (xp\phi_1 + x(1-p)\phi_2)dx\\
&= p\int_{-\infty}^\infty x\phi_1dx + (1-p)\int_{-\infty}^\infty x\phi_2dx\\
&= p\mu_1 + (1-p)\mu_2 && (1)\\
\end{align}

Para hallar la varianza, primero hallamos $\text{E}\left[X^2\right]$:

\begin{align}
\text{E}\left[X^2\right] &= \int_{-\infty}^\infty x^2(p\phi_1 + (1-p)\phi_2)dx\\
&= \int_{-\infty}^\infty (x^2p\phi_1 + x^2(1-p)\phi_2)dx\\
&= p\int_{-\infty}^\infty t^2\phi_1dt + (1-p)\int_{-\infty}^\infty t^2\phi_2dt\\
&= p\left(\text{E}\left[T_1^2\right] - \text{E}\left[T_1\right]^2 + \text{E}\left[T_1\right]^2\right)  + (1-p)\left(\text{E}\left[T_2^2\right] - \text{E}\left[T_2\right]^2 + \text{E}\left[T_2\right]^2\right) && \text{Definimos $T_i \sim N(\mu_i,\sigma_i^2)$}\\
&= p\left(\sigma_1^2 + \mu_1^2\right) + (1-p)\left(\sigma_2^2 + \mu_2^2\right) && (2)\\
\\
\text{Var}\left[X\right] &= \text{E}\left[X^2\right] - \text{E}\left[X\right]^2\\
&= p\left(\sigma_1^2 + \mu_1^2\right) + (1-p)\left(\sigma_2^2 + \mu_2^2\right) - \left(p\mu_1 + (1-p)\mu_2\right)^2 && \text{Usando $(1)$ y $(2)$}\\
\end{align}

b) Pruebe la siguiente propiedad:
Sea $W \sim \text{Bernoulli}(p)$ y $X$ otra v.a. tal que su distribución condicional a $W$ es dada por

$$X | W = 1 \sim \text{N}(\mu_1,\sigma_1^2)\\
X | W = 0 \sim \text{N}(\mu_2,\sigma_2^2)$$

entonces $X \sim \text{MN}(\mu_1,\mu_2,\sigma_1^2,\sigma_2^2)$.

Tenemos:

\begin{align}
f_W(w) &= \begin{cases}
p,  & \text{si $w = 1$} \\
1-p, & \text{si $w = 0$}
\end{cases} &(1)\\
f_X(x|w) & = \begin{cases}
\phi_1,  & \text{si $w = 1$} \\
\phi_2, & \text{si $w = 0$}
\end{cases} &(2)\\
\end{align}

Nos interesa calcular $f_X$, la densidad marginal de $X$. Usamos la regla de probabilidad total con la partición dada por los valores de $W$:

\begin{align}
f_X(x) &= f_{XW}(x,1) + f_{XW}(x,0)\\
&= f_W(1)f_{X}(x|1) + f_W(0)f_{X}(x|0) &\text{Regla del producto}\\
&= p\phi_1 + (1-p)\phi_2 &\text{Por definiciones $(1)$ y $(2)$}\\
&= p\phi(x|\mu_1,\sigma_1^2)+(1-p)\phi(x|\mu_2,\sigma_2^2)\\
&\mathbb{LISTO}\text{   }\mathbb{CAUSITA}
\end{align}

c) Utilice la propiedad dada en b) para proponer un algoritmo para simular valores de una v.a. $X \sim \text{MN}(\mu_1,\mu_2,\sigma_1^2,\sigma_2^2,p)$. Implemente el algoritmo propuesto en R. Simule 10 000 valores de una $\text{MN}(2,8,1,4,0.2$ y verifique mediante gráficos de histograma con función de densidad y cuantiles que el método propuesto funciona correctamente.

Una manera de simular $X$ consiste en generar primero un valor de $W$ y luego uno de $X|W=w$. El segundo valor tendrá la distribución deseada.

```{r}
n <- 10000
u <- c(2,8); sd <- c(1,4)
p <- 0.2

#Simular observaciones de W
w <- as.numeric(runif(n)>p)
#Simular observaciones de X|W
x <- rnorm(n,u[w+1],sd[w+1])
```

Procedemos a realizar la evaluación gráfica del ajuste de nuestros datos comparándolos con las curvas teóricas. 

```{r}
#Comparación mediante histograma
hist(x,probability = TRUE,ylim=c(0,0.12),breaks=25)
curve(p*dnorm(l,u[1],sd[1])+(1-p)*dnorm(l,u[2],sd[2]),add = TRUE, xname = "l")

#Comparación mediante gráfica de cuantiles

# 1. Calcular el cuantil de la distribucion teorica al
#    que pertenece cada valor simulado.
q_t <- p*pnorm(x,u[1],sd[1])+(1-p)*pnorm(x,u[2],sd[2])

# 2. Usar los cuantiles teoricos para extraer el valor
#    simulado correspondiente.
x_q <- quantile(x,q_t)

# 3. Comparar cada valor en su cuantil teórico contra
#    el valor hallado para ese cuantil en la simulación.
plot(x,x_q)
```

d) Presente los pasos que debe seguir el algoritmo de Metropolis-Hastings considerando como distribución generadora de candidatos una distribución normal centrada en el punto anterior. Implemente en R el algoritmo propuesto. Simule 10 000 valores de una $\text{MN}(2, 8, 1, 4, 0.2)$ y verifique mediante gráficos de cadenas, histograma con función de densidad y cuantiles que el método propuesto funciona correctamente.

```{r}
n <- 50000
s <- c(5,numeric(n))

u1 <- 2; u2 <- 8; sd1 <- 1; sd2 <- 4; p <-0.2

sdq <- 2.4

d_obj <- function(x){p*dnorm(x,u1,sd1)+(1-p)*dnorm(x,u2,sd2)}
d_can <- function(x,u){dnorm(x,u,sdq)}

alpha <- function(x,y,f,q){
  min(1,f(y)*q(x,y)/(f(x)*q(y,x)))
}

for(i in 1:(length(s)-1)){
  candidato <- rnorm(1,s[i],sdq)
  if(runif(1)<=alpha(s[i],candidato,d_obj,d_can)){
    s[i+1] <- candidato
  } else {
    s[i+1] <- s[i]
  }
  
}

s[(length(s)-9999):length(s)]

hist(s)
```
